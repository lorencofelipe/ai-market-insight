# PRD 01 ‚Äî RAG-Powered Market Intelligence Chat

## 1. Problema

O chat do AI Market Insight hoje usa apenas o conhecimento geral do LLM para responder perguntas de mercado. Isso causa:

- **Alucina√ß√µes**: Dados inventados sobre mercados, funding, concorrentes
- **Desatualiza√ß√£o**: Conhecimento limitado ao training cutoff do modelo
- **Sem fontes**: Usu√°rio n√£o consegue verificar a veracidade das respostas
- **Zero diferencia√ß√£o**: Qualquer ChatGPT/Gemini responde igual

> [!CAUTION]
> Sem RAG, o produto √© apenas um wrapper de LLM ‚Äî sem moat competitivo real.

---

## 2. Solu√ß√£o

Implementar **Retrieval-Augmented Generation (RAG)** para que o chat responda baseado em **dados reais de mercado** coletados pelos scripts de execu√ß√£o, reports, e fontes confi√°veis.

### Fluxo Proposto

```mermaid
graph LR
    A[Pergunta do Usu√°rio] --> B[Query Embedding]
    B --> C[Busca no Vector DB]
    C --> D[Top-K Documentos Relevantes]
    D --> E[Reranking]
    E --> F[LLM + Contexto Recuperado]
    F --> G[Resposta com Cita√ß√µes]
```

---

## 3. Escopo

### In-Scope (Must Have)
- Pipeline de ingest√£o: converter outputs dos scripts Python (`.tmp/*.json`) em embeddings
- Vector store no Supabase via `pgvector`
- Retrieval endpoint (Supabase Edge Function)
- Chat frontend com cita√ß√µes/fontes nas respostas
- Chunking inteligente por se√ß√£o de relat√≥rios

### Should Have
- Hybrid search (sem√¢ntico + keyword BM25)
- Reranking com cross-encoder
- Indicador de confian√ßa por resposta (baseado em similarity score)

### Could Have
- Upload de PDFs pelo usu√°rio (relat√≥rios de mercado)
- Scheduled re-indexing autom√°tico

### Out of Scope
- Fine-tuning de modelos de embedding
- Multi-tenancy de knowledge bases por usu√°rio (v2)

---

## 4. Arquitetura T√©cnica (3 Camadas)

### Layer 1 ‚Äî Directive
**Novo arquivo**: `directives/rag_pipeline.md`
- Define fluxo de ingest√£o, formatos aceitos, crit√©rios de chunking
- Regras de quando re-indexar dados
- Thresholds de relev√¢ncia para incluir/excluir contexto

### Layer 3 ‚Äî Execution
**Novos scripts**:

| Script | Fun√ß√£o |
|--------|--------|
| `execution/rag_ingest.py` | L√™ JSONs/textos do `.tmp/`, chunka, gera embeddings, insere no Supabase pgvector |
| `execution/rag_query.py` | Recebe query, busca documentos similares, retorna top-K com scores |

**Depend√™ncias** (adicionar ao `requirements.txt`):
```
sentence-transformers
pgvector
supabase
tiktoken
```

### Backend ‚Äî Supabase
- Extens√£o `pgvector` habilitada
- Tabela `documents`: `id`, `content`, `embedding`, `metadata`, `source`, `chunk_index`, `created_at`
- Fun√ß√£o SQL de busca por similaridade (cosine distance)
- Edge Function `rag-search` para expor via API

### Frontend
- Componente `SourceCitation.tsx` para exibir fontes inline
- Badge de confian√ßa (üü¢ Alta | üü° M√©dia | üî¥ Baixa) baseado em similarity score
- Fallback gracioso quando nenhum documento relevante √© encontrado

---

## 5. Modelo de Embeddings

| Modelo | Dimens√µes | Pr√≥s | Contras |
|--------|-----------|------|---------|
| `text-embedding-ada-002` (OpenAI) | 1536 | Alta qualidade, multil√≠ngue | Pago, depende de API |
| `all-MiniLM-L6-v2` | 384 | Gr√°tis, r√°pido, local | Qualidade inferior |
| `bge-large-en-v1.5` | 1024 | SOTA performance | Apenas ingl√™s |
| **`e5-large-v2`** ‚≠ê | 1024 | Alta qualidade, multil√≠ngue | Requer GPU para batch |

**Recomenda√ß√£o**: Come√ßar com `text-embedding-ada-002` pela simplicidade, migrar para modelo local quando volume justificar.

---

## 6. M√©tricas de Sucesso

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| **Respostas com cita√ß√µes** | >80% das respostas | % de respostas que incluem pelo menos 1 fonte |
| **Relev√¢ncia do retrieval** | MRR >0.7 | Mean Reciprocal Rank dos documentos recuperados |
| **Redu√ß√£o de alucina√ß√µes** | -60% | Avalia√ß√£o manual de amostra (antes vs depois) |
| **Lat√™ncia** | <3s p95 | Tempo total query ‚Üí resposta com retrieval |
| **Ado√ß√£o** | >50% dos chats | % de conversas que disparam retrieval |

---

## 7. Riscos e Mitiga√ß√µes

| Risco | Severidade | Mitiga√ß√£o |
|-------|-----------|-----------|
| Base de dados vazia no in√≠cio | Alta | Seed com dados dos scripts existentes + relat√≥rios p√∫blicos |
| Lat√™ncia alta com reranking | M√©dia | Cache de embeddings, limitar reranking a top-20 |
| Custo de API de embeddings | M√©dia | Batch processing, cache de embeddings j√° computados |
| Dados desatualizados | M√©dia | Metadata com timestamp, alertar quando dado >30 dias |

---

## 8. Estimativa RICE

| | Valor |
|---|---|
| **Reach** | 100% dos usu√°rios (chat √© feature central) |
| **Impact** | 3x (Massive ‚Äî transforma a proposta de valor) |
| **Confidence** | 80% (Medium ‚Äî RAG √© padr√£o comprovado) |
| **Effort** | 3 person-weeks |
| **RICE Score** | **(100 √ó 3 √ó 0.8) / 3 = 80** |

---

## 9. Crit√©rios de Aceite

- [ ] Dados dos scripts `competitor_discovery.py` e `framework_analysis.py` indexados no vector store
- [ ] Chat retorna respostas com pelo menos 1 cita√ß√£o quando dados relevantes existem
- [ ] Fallback para resposta sem RAG quando similarity score < threshold
- [ ] Lat√™ncia total < 3s para 95% das queries
- [ ] Badge de confian√ßa vis√≠vel no frontend
